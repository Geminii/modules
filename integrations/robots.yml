name: robots
description: A Nuxt.js module thats inject a middleware to generate a robots.txt file
long_description: >-
  A Nuxt.js module thats inject a middleware to generate a robots.txt file. A
  robots.txt file tells search engine crawlers which pages or files the crawler
  can or can't request from your site. This is used mainly to avoid overloading
  your site with requests
repo: nuxt-community/robots-module
npm: '@nuxtjs/robots'
type: module
icon: ''
github: 'https://github.com/nuxt-community/robots-module'
website: 'https://github.com/nuxt-community/robots-module'
learn_more: 'https://support.google.com/webmasters/answer/6062608?hl=en'
keywords: []
categories:
  - seo
labels:
  - community
maintainers:
  - name: Ricardo Gobbo de Souza
    github: ricardogobbosouza
    avatar: 'https://github.com/ricardogobbosouza.png'
